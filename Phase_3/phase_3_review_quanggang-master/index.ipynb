{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![review guy](https://media.giphy.com/media/3krrjoL0vHRaWqwU3k/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOC \n",
    "\n",
    "1. [Gradient Descent](#grad_desc)\n",
    "2. [Logistic Regression](#logistic)\n",
    "3. [Confusion Matrix](#con_mat)\n",
    "4. [Accuracy/Precision/Recall/F1](#more_metric)\n",
    "5. [auc_roc](#auc_roc)\n",
    "3. [Algos](#algos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: What is a loss function? (Explain it in terms of the relationship between true and predicted values) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A loss function measures how far a predicted value is from its true value. The function we use to find how bad our model did in prediction is typically called the loss function\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: What loss functions do we know and what types of data work best with each?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Mean Squared Error\n",
    "2. Mean Absolute Error\n",
    "3. Root Mean Absolute Error\n",
    "4. Log loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solidify our knowledge of gradient descent, we will use Sklearn's stochastic gradient descent algorithm for regression [SGDRegressor](https://scikit-learn.org/stable/modules/sgd.html#regression).   Sklearn classifiers share many methods and parameters, such as fit/predict, but some have useful additions.  SGDRegressor has a new method called partial_fit, which will allow us to inspect the calculated coefficients after each step of gradient descent.  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We will use the diabetes dataset for this task.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np\n",
    "\n",
    "data = load_diabetes(as_frame=True)\n",
    "X = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  \n",
       "0 -0.002592  0.019908 -0.017646  \n",
       "1 -0.039493 -0.068330 -0.092204  \n",
       "2 -0.002592  0.002864 -0.025930  \n",
       "3  0.034309  0.022692 -0.009362  \n",
       "4 -0.002592 -0.031991 -0.046641  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a SGDRegressor object and run partial fit on X and y. For now, pass the argument `penalty=None`\n",
    "sgdr = SGDRegressor(penalty = None)\n",
    "X_partial = sgdr.partial_fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.90079772,  0.14127048,  2.95340256,  2.52460837,  1.05847914,\n",
       "        0.85598129, -1.90874954,  2.0493228 ,  2.71275484,  2.41024177])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the coefficient array\n",
    "X_partial.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.4253308091041"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import mean_squared_error from metrics, and pass in the true ys, an array of predictions\n",
    "# and the agrument squared = False\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y, sgdr.predict(X), squared=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.24469145014339"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat the partial fit. Inspect, RMSE, coefficients.\n",
    "X_partial = sgdr.partial_fit(X,y)\n",
    "mean_squared_error(y, sgdr.predict(X), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.48699474,  0.24218959,  4.79751059,  3.90202023,  1.7047115 ,\n",
       "        1.3881232 , -3.16175882,  3.40099233,  4.48381474,  3.6207729 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_partial.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a coefficient, and explain the gradient descent update.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Together, let's plot the trajectory of one coefficient against the loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code'\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Compare that to a full fit of the SGDRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonarikupurathu/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1208: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  47.98314558,  -41.92421514,  279.63100036,  193.50054896,\n",
       "         32.65404958,    4.16366872, -157.09004024,  138.19003875,\n",
       "        245.70244215,  133.67440767])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code\n",
    "X_full = sgdr.fit(X,y)\n",
    "X_full.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='logistic'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of target do we feed the logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "X = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: What is the purpose of train/test split?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Why should we never fit to the test portion of our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training set using a standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Why is scaling our data important? For part of your answer, relate to one of the advantages of logistic regression over another classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model with logistic regression to the appropriate portion of our dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_scaled,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fit our classifier, the object `lr` has been filled up with information about the best fit parameters.  Take a look at the coefficients held in the `lr` object.  Interpret what their magnitudes mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.29889235, -0.54041862, -0.30207233, -0.38735468, -0.19621385,\n",
       "         0.45867598, -0.79952603, -0.90188999,  0.20049328,  0.3640117 ,\n",
       "        -1.21652703,  0.27525916, -0.55332383, -1.01461943, -0.28318111,\n",
       "         0.65216998,  0.15571842, -0.28236794,  0.17844343,  0.67822265,\n",
       "        -0.89136423, -0.9354801 , -0.70405271, -0.9031794 , -0.5836625 ,\n",
       "        -0.01014015, -0.76749254, -0.92696184, -0.84366397, -0.54416998]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the .coef_ attribute of lr and interpret\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18366501])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression has a predict method just like linear regression.  Use the predict method to generate a set of predictions (y_hat_train) for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use predict to generate a set of predictions\n",
    "y_hat_train = lr.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='con_mat'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrices are a great way to visualize the performance of our classifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: What does a good confusion matrix look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fd144057fd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a confusion matrix for our logistic regression model fit on the scaled training data\n",
    "plot_confusion_matrix(lr, X_train_scaled, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='more_metrics'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy/Precision/Recall/F_1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a bunch of additional metrics, most of which we can figure out from the CM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Define accuracy. What is the accuracy score of our classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,\\\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9882629107981221"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm accuracy in code\n",
    "accuracy_score(y_train, y_hat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Why might accuracy fail to be a good representation of the quality of a classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Define recall. What is the recall score of our classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9962546816479401"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm recall in code\n",
    "recall_score(y_train, y_hat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Define precision? What is the precision score of our classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9851851851851852"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm precision in code\n",
    "precision_score(y_train, y_hat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Define f1 score? What is the f1 score score of our classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9906890130353817"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_hat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='auc_roc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auc_Roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC_ROC curve can't be deduced from the confusion matrix.  Describe what the AUC_ROC curve shows. \n",
    "Look [here](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5) for some nice visualizations of AUC_ROC."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Describe the AUC_ROC curve.  What does a good AUC_ROC curve look like? What is a good AUC_ROC score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantages of logistic regression is that it generates a set of probabilities associated with each prediction.  What is the default threshold?  How would decrease or increasing your threshold affect true positive and false positive rates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For our scaled X_train, generate an array of probabilities associated with the probability of the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.11843692e-04, 9.94856860e-01, 7.84765405e-04, 9.99729437e-01,\n",
       "       8.95408991e-01, 9.98159550e-01, 1.93522299e-01, 1.09133339e-07,\n",
       "       6.32251982e-09, 9.94035704e-01, 9.99998601e-01, 9.99926389e-01,\n",
       "       1.39856352e-05, 9.99724101e-01, 2.68639360e-07, 9.99746300e-01,\n",
       "       9.99290178e-01, 9.98248873e-01, 9.98338703e-01, 2.79898386e-03,\n",
       "       3.35718205e-06, 9.35805283e-01, 9.99939007e-01, 4.72618846e-03,\n",
       "       9.86083310e-01, 1.74297828e-05, 4.61820349e-01, 9.99434107e-01,\n",
       "       9.99956324e-01, 1.30431576e-06, 6.89302317e-01, 8.84302949e-01,\n",
       "       9.37217682e-01, 9.99986652e-01, 9.99365197e-01, 9.99806256e-01,\n",
       "       2.25266178e-06, 9.50749265e-01, 5.88654793e-02, 9.86550637e-01,\n",
       "       4.26136387e-05, 9.06228772e-01, 8.56938201e-08, 9.99169259e-01,\n",
       "       1.34198161e-02, 9.99553063e-01, 9.99974629e-01, 9.70334759e-01,\n",
       "       8.69132369e-01, 2.79753763e-03, 9.55308793e-01, 9.70992944e-01,\n",
       "       9.99857432e-01, 9.93593486e-01, 9.99044704e-01, 7.32203239e-02,\n",
       "       9.99979199e-01, 9.99632677e-01, 9.48121339e-05, 7.71847159e-02,\n",
       "       9.99942644e-01, 9.98157410e-01, 8.63031297e-01, 9.99996145e-01,\n",
       "       9.99977078e-01, 9.66139571e-01, 9.91015600e-01, 6.31303694e-01,\n",
       "       1.09932383e-06, 2.90422339e-01, 1.99596193e-01, 1.14267231e-07,\n",
       "       7.51588377e-06, 4.90060690e-03, 9.97923128e-01, 1.45971110e-03,\n",
       "       9.98954570e-01, 3.53608365e-04, 9.78643385e-01, 6.04014456e-08,\n",
       "       8.45701088e-01, 8.05601004e-01, 9.98713011e-01, 9.78423396e-01,\n",
       "       2.67073936e-03, 9.99790665e-01, 3.11961369e-02, 7.32055732e-01,\n",
       "       9.99401626e-01, 8.08629576e-03, 9.99042400e-01, 2.74481139e-02,\n",
       "       9.99311354e-01, 1.10794368e-04, 9.99260426e-01, 1.46857680e-03,\n",
       "       6.69216911e-11, 9.99306637e-01, 1.62696180e-04, 9.80639054e-01,\n",
       "       8.60280210e-01, 9.98037479e-01, 3.24002229e-11, 9.99920565e-01,\n",
       "       1.20480904e-08, 9.71939116e-01, 8.65922022e-01, 9.52074117e-01,\n",
       "       9.99854028e-01, 3.56301476e-04, 8.93886420e-04, 9.73897835e-01,\n",
       "       9.95633669e-01, 3.59679274e-02, 3.46346022e-01, 4.43591057e-13,\n",
       "       1.08137450e-03, 9.99019653e-01, 4.87379736e-03, 9.99953241e-01,\n",
       "       9.99947549e-01, 9.66120701e-01, 9.99890103e-01, 1.18055578e-07,\n",
       "       9.99914027e-01, 9.99086023e-01, 9.99818746e-01, 9.99614837e-01,\n",
       "       2.37452250e-04, 9.99779409e-01, 8.44230415e-01, 9.99912344e-01,\n",
       "       7.61999269e-01, 9.99999829e-01, 9.99069451e-01, 9.86147342e-01,\n",
       "       9.76009987e-01, 8.87042856e-01, 1.05105364e-05, 9.99756728e-01,\n",
       "       9.99860277e-01, 9.98962215e-01, 2.28662374e-09, 9.88217182e-01,\n",
       "       6.66932550e-06, 9.97586694e-01, 9.99735730e-01, 9.97655450e-01,\n",
       "       9.99423422e-01, 9.87346060e-01, 9.99936045e-01, 9.99991044e-01,\n",
       "       4.75646960e-07, 9.95857681e-01, 9.90516437e-01, 9.98554959e-01,\n",
       "       2.83989489e-01, 9.30456861e-01, 9.99997137e-01, 3.91094731e-07,\n",
       "       9.99404074e-01, 9.99950958e-01, 2.58145908e-02, 9.99428058e-01,\n",
       "       3.65267510e-01, 9.99505357e-01, 9.99474633e-01, 9.97163639e-01,\n",
       "       1.89851143e-01, 5.01650203e-01, 8.82265461e-01, 1.84250294e-01,\n",
       "       9.89110745e-01, 2.96637498e-02, 9.54764063e-01, 9.99979029e-01,\n",
       "       2.11453641e-06, 9.55718012e-01, 1.59660415e-04, 9.99998495e-01,\n",
       "       3.69323813e-03, 9.98116716e-01, 5.86877291e-05, 9.98070588e-01,\n",
       "       9.99836736e-01, 9.62959409e-01, 9.71776196e-01, 9.99855281e-01,\n",
       "       9.36516007e-01, 9.97963866e-01, 9.98703317e-01, 1.33218454e-03,\n",
       "       9.94970701e-01, 1.44362084e-09, 3.96952858e-01, 9.89108824e-01,\n",
       "       2.11395305e-09, 5.80038120e-06, 9.94431991e-01, 1.68978923e-02,\n",
       "       9.95409511e-01, 9.98924584e-01, 9.99583124e-01, 9.99707388e-01,\n",
       "       9.94526423e-01, 9.98050301e-01, 1.64468980e-05, 9.99970135e-01,\n",
       "       8.26874302e-01, 1.65638021e-11, 9.99586515e-01, 4.79043998e-06,\n",
       "       9.99532983e-01, 4.16590617e-03, 9.99925512e-01, 6.07304388e-01,\n",
       "       1.97619304e-05, 5.06079603e-02, 1.48525270e-09, 7.39433137e-03,\n",
       "       9.97874277e-01, 3.23699475e-06, 9.99988223e-01, 8.70460998e-02,\n",
       "       9.99539600e-01, 6.74413987e-01, 9.99988146e-01, 9.99913210e-01,\n",
       "       5.78993064e-03, 9.97743001e-01, 9.88247453e-01, 1.78863439e-01,\n",
       "       9.49966467e-01, 2.36646799e-06, 9.99908928e-01, 9.99817559e-01,\n",
       "       9.95695728e-01, 2.41869362e-06, 1.60468766e-04, 1.16774518e-01,\n",
       "       9.81571928e-01, 1.69446482e-08, 3.42276301e-01, 9.98598581e-01,\n",
       "       9.88595592e-01, 9.99943362e-01, 9.98503100e-01, 9.99326310e-01,\n",
       "       8.99566156e-01, 4.01338197e-04, 8.51711355e-01, 1.59416048e-03,\n",
       "       9.98734429e-01, 8.53633823e-02, 9.80388991e-01, 9.70920136e-01,\n",
       "       9.97218338e-01, 9.66615410e-01, 9.78255139e-01, 1.00948774e-05,\n",
       "       9.98589322e-01, 1.03575284e-01, 9.95413251e-01, 6.56500350e-03,\n",
       "       1.59488226e-06, 8.74638686e-13, 8.90433997e-01, 9.99484383e-01,\n",
       "       9.83668396e-01, 9.96958169e-01, 1.05789267e-05, 2.31687284e-03,\n",
       "       9.96781025e-01, 9.99747403e-01, 9.99432828e-01, 9.75132116e-01,\n",
       "       9.99755914e-01, 9.99197514e-01, 6.76816450e-05, 9.93889508e-01,\n",
       "       9.99651202e-01, 7.32401170e-07, 9.75094132e-01, 2.12042605e-07,\n",
       "       9.85036511e-01, 9.99808865e-01, 9.99995390e-01, 9.97616100e-01,\n",
       "       9.99880492e-01, 9.99977072e-01, 6.87469389e-01, 9.80618898e-01,\n",
       "       1.10758660e-04, 8.32831972e-01, 1.17313545e-04, 3.62909453e-09,\n",
       "       5.93924177e-04, 4.27235546e-03, 9.64486866e-01, 7.92472999e-02,\n",
       "       9.98898620e-01, 9.92710125e-01, 2.04133084e-08, 1.12794652e-07,\n",
       "       9.98280726e-01, 9.99830776e-01, 9.99855724e-01, 9.98249395e-01,\n",
       "       9.94447076e-01, 9.91586469e-01, 8.76922545e-01, 9.92096358e-01,\n",
       "       2.34743253e-03, 9.59040715e-01, 2.14472725e-03, 9.98494652e-01,\n",
       "       9.99043173e-01, 8.94511764e-01, 9.99915901e-01, 4.40746600e-12,\n",
       "       9.99704131e-01, 9.93714014e-01, 1.23714775e-01, 1.41537808e-03,\n",
       "       9.98772666e-01, 9.99901039e-01, 3.10259372e-03, 9.96342984e-01,\n",
       "       9.86973474e-01, 9.77780349e-01, 9.02183189e-01, 9.99870607e-01,\n",
       "       9.20825310e-01, 1.80734626e-04, 9.82251629e-01, 9.48423220e-06,\n",
       "       2.09013826e-02, 3.12248093e-08, 9.99439970e-01, 9.72530703e-01,\n",
       "       3.21890117e-08, 9.99723164e-01, 5.02668156e-23, 1.26500018e-12,\n",
       "       6.30727042e-01, 4.65763465e-02, 1.13798474e-08, 9.99273732e-01,\n",
       "       9.99964299e-01, 9.95433512e-01, 1.05770810e-04, 9.99989358e-01,\n",
       "       3.10254338e-04, 7.66974373e-01, 9.70633105e-01, 9.99279078e-01,\n",
       "       9.86794534e-01, 9.63990800e-01, 3.07862305e-07, 1.33171898e-07,\n",
       "       9.89830036e-01, 5.82630943e-03, 2.38401541e-10, 9.99433686e-01,\n",
       "       9.51249596e-01, 9.90738537e-01, 5.64944296e-06, 1.21228354e-01,\n",
       "       1.62665354e-10, 9.97446078e-01, 9.95541730e-01, 6.56920152e-06,\n",
       "       2.80436731e-06, 2.59653402e-04, 9.97842501e-01, 8.51415052e-03,\n",
       "       1.68951276e-06, 9.99999919e-01, 9.95553399e-01, 8.51137128e-01,\n",
       "       9.93422756e-01, 9.99153293e-01, 3.26441652e-02, 9.99946486e-01,\n",
       "       9.99966245e-01, 9.92868073e-01, 5.86185592e-04, 9.98553002e-01,\n",
       "       6.99133907e-01, 9.92876555e-01, 9.99892464e-01, 1.02570209e-01,\n",
       "       9.99242824e-01, 9.99957812e-01, 7.42071599e-01, 4.72862915e-02,\n",
       "       9.98261282e-01, 1.92763357e-06, 1.83343925e-10, 9.99725642e-01,\n",
       "       9.97822046e-01, 9.89375457e-01, 9.99495747e-01, 9.32660745e-05,\n",
       "       9.97383504e-01, 5.33728833e-04, 9.99760073e-01, 9.99794495e-01,\n",
       "       4.58954135e-01, 6.09258237e-04, 9.96893486e-01, 5.46044858e-06,\n",
       "       9.80852292e-01, 7.62896158e-05, 1.13410816e-07, 3.32783775e-01,\n",
       "       9.99063750e-01, 9.79743535e-01, 8.49380747e-01, 9.98788376e-01,\n",
       "       9.57809264e-01, 1.35791959e-06, 9.99969878e-01, 2.11056001e-09,\n",
       "       8.38207620e-03, 9.94918371e-01])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "lr.predict_proba(X_train_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using those probabilities, create two arrays, one which converts the probabilities to label predictions using the default threshold, and one using a threshold of .4.  How does it affect our metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x7fd1440a0160>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the AUC_ROC curve for our classifier\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "plot_roc_curve(lr, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='algos'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of the sklearn syntax is shared across classifiers and regressors.  Fit, predict, score, and more are methods associated with all sklearn classifiers.  They work differently under the hood. KNN's fit method simply stores the training set in memory. Logistic regressions .fit() does the hard work of calculating coefficients. \n",
    "\n",
    "![lazy_george](https://media.giphy.com/media/8TJK6prvRXF6g/giphy.gif)\n",
    "\n",
    "However, each algo also has specific parameters and methods associated with it.  For example, decision trees have feature importances and logistic has coefficients. KNN has n_neighbors and decision trees has max_depth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting to know the algo's and their associated properties is an important area of study. \n",
    "\n",
    "That being said, you now are getting to the point that no matter which algorithm you choose, you can run the code to create a model as long as you have the data in the correct shape. Most importantly, the target is the appropriate form (continuous/categorical) and is isolated from the predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the algos we know so far. \n",
    " - Linear Regression\n",
    " - Lasso/Ridge Regression\n",
    " - Logistic Regression\n",
    " - Naive-Bayes\n",
    " - KNN\n",
    " - Decision Trees\n",
    " \n",
    "> Note that KNN and decision trees also have regression classes in sklearn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are two datasets from seaborn and sklearn.  Let's work through the process of creating simple models for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "penguins = sns.load_dataset('penguins')\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question: What algorithm would be appropriate based on the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split target from predictors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For the first simple model, let's just use the numeric predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate numeric predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale appropriately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate appropriate model and fit to appropriate part of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of predictions\n",
    "\n",
    "y_hat_train = None\n",
    "y_hat_test = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and analyze appropriate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    "X = pd.DataFrame(data['data'], columns = data['feature_names'])\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question: What algorithm would be appropriate based on the target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split target from predictors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For the first simple model, let's just use the numeric predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate numeric predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale appropriately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate appropriate model and fit to appropriate part of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of predictions\n",
    "\n",
    "y_hat_train = None\n",
    "y_hat_test = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and analyze appropriate metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
